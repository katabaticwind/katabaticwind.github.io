---
layout: post
title:  "ICML 2019: Invited Talks"
date: 2019-06-17 11:03
---

Last week I attended the International Conference on Machine Learning (ICML) in Long Beach, CA. ICML is one of the most important conferences on machine learning in the world, attracting paper submissions and hosting invited talks by top researchers in the field, such as Yann LeCun and David Silver, as well as small armies of researchers from industry outfits such as DeepMind, OpenAI, and Google Brain. In the coming weeks I'll be writing about the papers I thought were most interesting and inspiring, but for now I thought I might give a little summary of the invited talks. These talks aren't really machine learning talks per se, but they encourage listeners to think about how machine learning is used in the real world, and perhaps to reflect and consider a bigger picture for a few minutes.

## Tuesday, June 11: John Abowd
This was my first time attending ICML, and I didn't know exactly what to expect. There was an optional tutorial session on Monday, but I decided to skip this and attend the workshops at the end of the week instead. The conference officially kicked off on Tuesday with an invited talk by John Abowd. John is an economist (possibly the only other economist by training at the conference other than myself) who is currently the U.S. Census Bureau's associate director of research and methodology. I went to the talk with the expectation that it would be boring because, well, it's the Census Bureau. But in fact the bureau faces a challenging problem, which is figuring out how to provide data (statistics) to users in useful while maintaining the privacy of its respondents. It turns out that there is a *fundamental* trade-off between information and privacy: if you publish too many statistics too accurately, then no one has any privacy (and, conversely, perfect privacy implies *worthless* data). John calls the "Fundamental Law of Information Recovery".

Essentially, the more statistics the bureau provides, the easier it is to match respondents against commercially available datasets (a "[reconstruction attack](https://queue.acm.org/detail.cfm?id=3295691)"). To alleviate this problem, the Census Bureau adds randomness to the statistics it provides (or to the data used to generate statistics), which obviously reduces the accuracy of the statistics. This process is known as [differential privacy](https://en.wikipedia.org/wiki/Differential_privacy), and John and his team have done a lot of great work putting this concept into practice at the Census Bureau, but at the end of the day someone will still need to decide how to balance privacy against accuracy--a task for which there is no guideline or mandate. None of this really means much to me, but it seems like an interesting line of research, and it is certainly important to Facebook, Google, and generally any group collecting large amounts of data about private data. If you're interested, this [paper](https://arxiv.org/abs/1809.02201) describes some of the challenges John and his colleagues have encountered incorporating differential privacy at the Census Bureau. (If you're *really* interested, the complete 1940 census records have been available since 2012 if you want to play around with this stuff—you can find the data [here](https://1940census.archives.gov/index.asp)).

## Wednesday, June 12: Aude Billard
The following day featured an invited talk by Aude Billard entitled "Machine Learning for Robots to Think Fast". Dr. Billard is the head of the [LASA laboratory](http://lasa.epfl.ch) at the École Polytechnique Fédérale de Lausanne in Switzerland. She is one of the world's leading experts in robotics. Her talk demonstrated a series of tasks that her lab had "trained" robotic arms to perform. In one task, a single arm—which includes a dexterous hand—tries to [catch objects](https://www.youtube.com/watch?v=JEob5Slkvjw) thrown in its direction. The researchers started by throwing objects that are simple to catch, like a small ball, and then moved on to more difficult items such as a tennis racquet or a half-full (or was it half-empty?) bottle of water. With the simple objects, the flight path is easier to predict, but the robot still needs to make a quick calculation to determine how to move its hand to meet the object. Catching a half-full bottle of water is more challenging because its path is irregular, and the robot may need to make a last-minute adjustment to its hand position to catch the bottle.

There seem to be two keys to the robots success in this task. First, the researchers use direct demonstrations to teach the robot, that is, they throw the object and manually move the robot's arm into position so that it experiences an approximately correct motion. Second, they combine physical modeling (dynamical systems) with machine learning techniques (e.g., Gaussian mixture models, support vector machines, and nonlinear/extended Kalman filters) to learn a model of the world. It's a rather elegant—and clearly effective—combination of machine learning and applied mathematics, and a superb example of how machine learning compliments traditional science, especially in practical applications. (If this is sounds interesting, slides and code from a tutorial her lab recently led can be found [here](https://epfl-lasa.github.io/TutorialICRA2019.io/)).

In another task, a pair of robotic arms learn to [peel vegetables](https://www.youtube.com/watch?v=xIK6U52TjRM), which requires coordination between the arms as well as adaptation to the changes to the vegetable as it is peeled. At the end of the talk, Dr. Billard was asked what the biggest challenge in robotics is, and her answer was "general object manipulation", and in particular the ability to handle objects and perform tasks that change the object's shape.

## Thursday, June 13: Alison Gopnik
Thursday morning featured an invited talk by cognitive psychologist and child cognition expert Alison Gopnik. Measured by audience engagement, this was the most popular invited talk of the conference, which might be because it was the least technical, and therefore best understood. Dr. Gopnik talked about how children learn and think in comparison with the adult mind, and suggested that researchers in the field of machine learning would do well to focus more on replicating the prior than the latter. I don't think we want to make machines that function like children—children aren't generally too reliable—but I can see the desirability of machines that *learn* like children.

Learning in childhood is characterized by three processes. First, children learn by building abstract causal models from data. They perform this task sub-consciously apparently, as we don't believe any four-year olds explicitly understand graphical models, but their responses during carefully designed experiments are often consistent with Bayesian inference. (I don't think this fact is too surprising or even unique to the child mind, but it's at least a "promising feature" if we're thinking of children as a model for learning). Second, children engage in an active learning process. You *can* show children how to do things, but a considerable amount of what children learn to do is the result of trial and error. Children tend to explore more than adults. In an interesting experiment, children and adults select from a few boxes and receive rewards that depend on the box chosen. One box might be high-reward, high-risk, while another box might be low-risk, low-reward. Essentially, the subjects solve a one-armed bandit problem. What the researchers found is that children are more likely to test unlikely—but true—conclusions. In other words, children are much more likely to keep selecting boxes that have provided small rewards, which are the boxes (in one setup) that periodically deliver really big rewards. In contrast, after one or two small rewards adults will decide that such boxes should be avoided. As a result, the *long run* strategies of children often outperform those of the adults.

This idea isn't new to researchers of reinforcement learning, where the the exploration-exploitation trade-off is understood to be crucially important. Children appear to be something like algorithms in their early stage: they do a lot of random shit, some of which ends up working. Adults act like algorithms in their later stages, rarely performing random actions, but instead exploiting their knowledge (or often just being stuck in a sub-optimal routine). And it seems that this stodgy learning style sets in fairly early in life, certainly by the time kids enter high school. It makes me think about my experience trying to teach college students, who (in my experience) always want to be told precisely how to do things, and never want to experiment. (It's amazing how much pushback you will get for encouraging a students to try to figure things out on their own, *especially* from faculty). On the other hand, experimentation is the nature of the scientist: keep trying new ideas and approaches. Perhaps a goal that we could all aspire to is to make time to pursue ideas **with no expectation of reward**. Just do something because it seems interesting and see what happens. Probably nothing, but its not a waste of time. In fact, this should probably be thought of as one of the key roles of universities: to provide a space for researchers to *fail*.
